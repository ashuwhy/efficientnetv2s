{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# This script will train a model on 7 waste categories using EfficientNetV2S\n",
        "# compatible with the SWMRO backend and optimized for Mac M2\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import sklearn\n",
        "from PIL import Image as im\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "\n",
        "# Set seeds to make the experiment more reproducible.\n",
        "import random\n",
        "def seed_everything(seed = 0):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "seed = 0\n",
        "seed_everything(seed)\n",
        "\n",
        "# For Google Colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    data_path = '/content/drive/MyDrive/swmro/dataset'\n",
        "except ImportError:\n",
        "    # For local execution\n",
        "    data_path = './dataset'\n",
        "\n",
        "# EfficientNetV2S input size is 384x384, but we can use 224x224 for faster training\n",
        "# and compatibility with other models\n",
        "BATCH_SIZE = 32  # Reduced batch size for EfficientNetV2S which is larger\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "\n",
        "input_path = data_path\n",
        "train_data_dir = os.path.join(input_path, 'train')\n",
        "test_data_dir = os.path.join(input_path, 'test')\n",
        "\n",
        "# Print the class names to verify\n",
        "class_names = sorted(os.listdir(train_data_dir))\n",
        "print(\"Training on these classes:\", class_names)\n",
        "\n",
        "# Verify that the class names match what we expect\n",
        "expected_classes = ['cardboard', 'compost', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
        "assert all(c in class_names for c in expected_classes), \"Missing expected classes\"\n",
        "\n",
        "# Data augmentation - more extensive for EfficientNetV2S\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip('horizontal_and_vertical', input_shape=(img_height, img_width, 3)),\n",
        "    layers.RandomRotation(0.3, fill_mode='nearest'),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomContrast(0.2),\n",
        "    layers.RandomBrightness(0.2),\n",
        "])\n",
        "\n",
        "# Load and prepare datasets\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_data_dir,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'training',\n",
        "    label_mode = 'categorical',\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    seed = 123)\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_data_dir,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'validation',\n",
        "    label_mode = 'categorical',\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    seed = 123)\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(\"Class names from dataset:\", class_names)\n",
        "\n",
        "# Visualize sample images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(min(9, len(class_names))):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[i])\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "# Visualize augmented images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(min(9, len(class_names))):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "# Performance optimization\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Create the base model from EfficientNetV2S\n",
        "IMG_SHAPE = (img_height, img_width, 3)\n",
        "base_model = tf.keras.applications.EfficientNetV2S(\n",
        "    input_shape=IMG_SHAPE,\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# Freeze base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build the model\n",
        "n_classes = len(class_names)\n",
        "print(f\"Number of classes: {n_classes}\")\n",
        "\n",
        "# Create model with EfficientNetV2S\n",
        "model = Sequential([\n",
        "    data_augmentation,\n",
        "    layers.Rescaling(1./255),  # Normalize pixel values\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.BatchNormalization(),  # Added for better stability\n",
        "    layers.Dense(512, activation='relu'),  # Increased from 256 to 512 for EfficientNetV2S\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(n_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Compile with a lower initial learning rate for EfficientNetV2S\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Model Checkpoint - use .keras format for newer TensorFlow versions\n",
        "tl_checkpoint_1 = ModelCheckpoint(\n",
        "    filepath='efficientnetv2s_waste_classifier.keras',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# EarlyStopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=7,  # Increased patience for EfficientNetV2S\n",
        "    restore_best_weights=True,\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "# ReduceLROnPlateau\n",
        "rop_callback = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    factor=0.5,\n",
        "    min_lr=0.00001\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=30,  # Increased epochs for EfficientNetV2S\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[tl_checkpoint_1, early_stop, rop_callback]\n",
        ")\n",
        "\n",
        "# Plot training history\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "# Evaluate on test data\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_data_dir,\n",
        "    label_mode='categorical',\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seed=123\n",
        ")\n",
        "\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Load best weights and evaluate\n",
        "model.load_weights('efficientnetv2s_waste_classifier.keras')\n",
        "test_loss, test_acc = model.evaluate(test_ds, verbose=1)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Fine-tuning\n",
        "# Unfreeze the top layers of the base model\n",
        "fine_tune_model = model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Freeze early layers, unfreeze later layers\n",
        "# For EfficientNetV2S, we'll unfreeze the last few blocks\n",
        "for layer in base_model.layers:\n",
        "    # Only make the last 30% of layers trainable\n",
        "    if isinstance(layer.name, str) and ('block6' in layer.name or 'block7' in layer.name):\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "# Recompile with lower learning rate\n",
        "fine_tune_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),  # Very low learning rate for fine-tuning\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Fine-tuning checkpoint\n",
        "ft_checkpoint = ModelCheckpoint(\n",
        "    filepath='efficientnetv2s_waste_classifier_fine_tuned.keras',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train with fine-tuning\n",
        "ft_history = fine_tune_model.fit(\n",
        "    train_ds,\n",
        "    epochs=15,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[ft_checkpoint, early_stop, rop_callback]\n",
        ")\n",
        "\n",
        "# Evaluate fine-tuned model\n",
        "fine_tune_model.load_weights('efficientnetv2s_waste_classifier_fine_tuned.keras')\n",
        "ft_test_loss, ft_test_acc = fine_tune_model.evaluate(test_ds, verbose=1)\n",
        "print(f\"Fine-tuned test accuracy: {ft_test_acc:.4f}\")\n",
        "\n",
        "# Save the final model\n",
        "fine_tune_model.save('efficientnetv2s_waste_classifier_final.keras', save_format='keras')\n",
        "\n",
        "# For backward compatibility, also save in h5 format\n",
        "try:\n",
        "    fine_tune_model.save('efficientnetv2s_waste_classifier_final.h5')\n",
        "    print(\"Also saved model in .h5 format for backward compatibility\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not save in .h5 format: {e}\")\n",
        "\n",
        "# Create a mapping dictionary to show how detailed classes map to backend categories\n",
        "mapping = {\n",
        "    'cardboard': 'RECYCLABLE',\n",
        "    'glass': 'RECYCLABLE',\n",
        "    'metal': 'RECYCLABLE',\n",
        "    'paper': 'RECYCLABLE',\n",
        "    'plastic': 'RECYCLABLE',\n",
        "    'compost': 'ORGANIC',\n",
        "    'trash': 'GENERAL'\n",
        "}\n",
        "\n",
        "print(\"\\nClass mapping for backend integration:\")\n",
        "for detailed, backend in mapping.items():\n",
        "    print(f\"{detailed} -> {backend}\")\n",
        "\n",
        "print(\"\\nSaved models:\")\n",
        "print(\"- efficientnetv2s_waste_classifier.keras: Base model\")\n",
        "print(\"- efficientnetv2s_waste_classifier_fine_tuned.keras: Fine-tuned model\")\n",
        "print(\"- efficientnetv2s_waste_classifier_final.keras: Final saved model\")\n",
        "print(\"- efficientnetv2s_waste_classifier_final.h5: Final saved model (h5 format)\")\n",
        "\n",
        "# Download the model to your local machine\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('efficientnetv2s_waste_classifier_final.keras')\n",
        "    files.download('efficientnetv2s_waste_classifier_final.h5')\n",
        "except ImportError:\n",
        "    print(\"Not running in Colab, skipping download\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Waste_Garbage_Collection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
